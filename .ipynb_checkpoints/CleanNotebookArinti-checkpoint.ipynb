{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('20200124_ews_observations.csv', low_memory=False)\n",
    "df = df.dropna()\n",
    "df['ObservationDate'] = pd.to_datetime(df['ObservationDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that deletes the unnecessary columns so that only columns with numbers are kept and the datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_scores(df):\n",
    "    df = df.drop(['SBP_Score', 'SpO2_Score', 'HR_Score', 'TEMP_Score', 'RR_Score', 'EwsProcedure', 'Add_O2', 'LOC'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that returns a dataframe of the patient and some info about the measurements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_patient (df, id_nr, plot=False):\n",
    "    # only select rows from the patient\n",
    "    patient = df.loc[df['PatientId'] == id_nr]\n",
    "    patient = patient.sort_values(by='ObservationDate', ascending=True)\n",
    "    # datetime as index\n",
    "    patient = patient.set_index('ObservationDate')\n",
    "    # drop NAN values and check how many samples are useful\n",
    "    patient = patient.dropna()\n",
    "    n_measurements = patient.shape[0]\n",
    "    print(f\"Number of measurements: {n_measurements}\")\n",
    "    \n",
    "    patient = patient.drop(['EwsProcedure'], axis=1)\n",
    "    \n",
    "    # print the info\n",
    "    if n_measurements > 1:\n",
    "        # print average minimum and maximum time between measurements\n",
    "        delta_t = patient.index.to_series().diff().dt.seconds.div(3600, fill_value=0)\n",
    "        delta_t_avg = delta_t.mean()\n",
    "        delta_t_max = delta_t.max()\n",
    "        delta_t_min = delta_t.nsmallest(2).iloc[1]\n",
    "        print(f\"Average time (hours) between measurements of patient {id_nr}: {delta_t_avg}\")\n",
    "        print(f\"Max diff time between measurements: {delta_t_max}\")\n",
    "        print(f\"Min diff time between measurements: {delta_t_min}\")\n",
    "        \n",
    "        # print start and end date of hospitalisation\n",
    "        start_date = patient.index.values[0]\n",
    "        end_date = patient.index.values[-1]\n",
    "        print(f\"Start_date: {start_date}\")\n",
    "        print(f\"End_date: {end_date}\")\n",
    "        \n",
    "        # check how many data we have on the patient\n",
    "        delta_t = end_date - start_date\n",
    "        delta_days = delta_t.astype('timedelta64[D]').astype('str')\n",
    "        # delta_days prints \"xx days\"\n",
    "        # next line cuts \" days\" out of the string delta_days\n",
    "        delta_days = delta_days[:len(delta_days) - 5]\n",
    "        print(f\"Hospitalisation duration: {delta_days}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Only 1 measurement\")\n",
    "    \n",
    "    \n",
    "    if int(delta_days) >= 2 and n_measurements >= 15:\n",
    "        to_predict = True\n",
    "        print(\"This patient has enough data to apply an accurate model\")\n",
    "    else:\n",
    "        to_predict = False\n",
    "        print(\"Not enough data yet to predict EWS\")\n",
    "    \n",
    "    # plot timeseries\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "        sns.lineplot(data=patient, x=\"ObservationDate\", y='EWS_Total', linestyle='-', color='grey', ax=ax)\n",
    "        sns.scatterplot(data=patient, x=\"ObservationDate\", y='EWS_Total', marker='o', linestyle='-', hue=\"Add_O2_Score\", palette=\"tab10\", ax=ax)\n",
    "    \n",
    "    return patient, n_measurements, to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of measurements: 272\n",
      "Average time (hours) between measurements of patient 1092: 6.416708537581695\n",
      "Max diff time between measurements: 23.004444444444445\n",
      "Min diff time between measurements: 0.007222222222222222\n",
      "Start_date: 2019-06-03T15:04:00.000000000\n",
      "End_date: 2019-12-09T08:24:41.000000000\n",
      "Hospitalisation duration: 188\n",
      "This patient has enough data to apply an accurate model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>EWS_Total</th>\n",
       "      <th>SBP</th>\n",
       "      <th>SBP_Score</th>\n",
       "      <th>LOC</th>\n",
       "      <th>LOC_Score</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>SpO2_Score</th>\n",
       "      <th>Add_O2</th>\n",
       "      <th>Add_O2_Score</th>\n",
       "      <th>HR</th>\n",
       "      <th>HR_Score</th>\n",
       "      <th>RR</th>\n",
       "      <th>RR_Score</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ObservationDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-03 15:04:00</th>\n",
       "      <td>1092</td>\n",
       "      <td>2</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03 20:11:31</th>\n",
       "      <td>1092</td>\n",
       "      <td>2</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-04 07:07:14</th>\n",
       "      <td>1092</td>\n",
       "      <td>5</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-04 16:47:11</th>\n",
       "      <td>1092</td>\n",
       "      <td>2</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-05 07:23:21</th>\n",
       "      <td>1092</td>\n",
       "      <td>4</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PatientId  EWS_Total    SBP  SBP_Score    LOC  LOC_Score  \\\n",
       "ObservationDate                                                                 \n",
       "2019-06-03 15:04:00       1092          2  160.0        0.0  ALERT          0   \n",
       "2019-06-03 20:11:31       1092          2  152.0        0.0  ALERT          0   \n",
       "2019-06-04 07:07:14       1092          5  176.0        0.0  ALERT          0   \n",
       "2019-06-04 16:47:11       1092          2  167.0        0.0  ALERT          0   \n",
       "2019-06-05 07:23:21       1092          4  176.0        0.0  ALERT          0   \n",
       "\n",
       "                     SpO2  SpO2_Score Add_O2  Add_O2_Score  HR  HR_Score  RR  \\\n",
       "ObservationDate                                                                \n",
       "2019-06-03 15:04:00  92.0         0.0   True           2.0  73         0  18   \n",
       "2019-06-03 20:11:31  90.0         0.0   True           2.0  74         0  18   \n",
       "2019-06-04 07:07:14  96.0         2.0   True           2.0  72         0  18   \n",
       "2019-06-04 16:47:11  92.0         0.0   True           2.0  70         0  18   \n",
       "2019-06-05 07:23:21  96.0         2.0   True           2.0  70         0  19   \n",
       "\n",
       "                     RR_Score  TEMP  TEMP_Score  \n",
       "ObservationDate                                  \n",
       "2019-06-03 15:04:00         0  36.4           0  \n",
       "2019-06-03 20:11:31         0  37.0           0  \n",
       "2019-06-04 07:07:14         0  36.0           1  \n",
       "2019-06-04 16:47:11         0  36.5           0  \n",
       "2019-06-05 07:23:21         0  36.3           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientx = analyse_patient(df, 1092)\n",
    "patientx[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that returns a dictionary of the d values of the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_diffs(df_patient):\n",
    "    from pmdarima.arima.utils import ndiffs\n",
    "    n_diffs_dict  = {}\n",
    "    metrics = ['SBP', 'SpO2', 'HR', 'RR', 'TEMP']\n",
    "    for column in metrics:\n",
    "        y = df_patient[column]\n",
    "        n_diffs = ndiffs(y, test='adf')\n",
    "        n_diffs_dict[column] = n_diffs\n",
    "    return n_diffs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that returns a dictionary of the parameters of the models for each of the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_pdq(df_patient):\n",
    "    from pmdarima.arima import auto_arima\n",
    "    metric_pdq_dict = {}\n",
    "    dict_ndiffs = n_diffs(df_patient)\n",
    "    for metric in dict_ndiffs:\n",
    "        ndiffs = dict_ndiffs[metric]\n",
    "        best_pdq = auto_arima(df_patient[metric], d=ndiffs, trace=False)\n",
    "        metric_pdq_dict[metric] = best_pdq.order\n",
    "    return metric_pdq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# def pdq(df_patient):\n",
    "#     from pmdarima.arima import auto_arima\n",
    "#     metric_pdq_dict = {}\n",
    "#     dict_ndiffs = n_diffs(df_patient)\n",
    "#     for metric in dict_ndiffs:\n",
    "#         X = df_patient[metric]\n",
    "#         print(X)\n",
    "#         size = int(len(X) * 0.66)\n",
    "#         train, test = X[0:size], X[size:len(X)]\n",
    "#         ndiffs = dict_ndiffs[metric]\n",
    "#         model = auto_arima(train, d=ndiffs, trace=False)\n",
    "#         preds, conf_int = model.predict(n_periods=test.shape[0], return_conf_int=True)\n",
    "#         print(f\"Test RMSE {metric}: {np.sqrt(mean_squared_error(test, preds))}\" )\n",
    "        \n",
    "#         # Plot the points and the forecasts\n",
    "#         x_axis = np.arange(train.shape[0] + preds.shape[0])\n",
    "#         x_years = x_axis + 1821  # Year starts at 1821\n",
    "\n",
    "#         plt.plot(x_years[x_axis[:train.shape[0]]], train, alpha=0.75)\n",
    "#         plt.plot(x_years[x_axis[train.shape[0]:]], preds, alpha=0.75)  # Forecasts\n",
    "#         plt.scatter(x_years[x_axis[train.shape[0]:]], test,\n",
    "#             alpha=0.4, marker='x')  # Test data\n",
    "#         plt.fill_between(x_years[x_axis[-preds.shape[0]:]],\n",
    "#                  conf_int[:, 0], conf_int[:, 1],\n",
    "#                  alpha=0.1, color='b')\n",
    "#         plt.title(\"Lynx forecasts\")\n",
    "#         plt.xlabel(\"Year\")\n",
    "#     return metric_pdq_dict\n",
    "# pdq(patientx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that models and fits an ARIMA model for each of the metrics and also plots things**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_and_predict(df_patient):\n",
    "    from pmdarima.arima import ARIMA\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    from math import sqrt, floor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from statistics import mean\n",
    "    \n",
    "    metrics = ['SBP', 'SpO2', 'HR', 'RR', 'TEMP']\n",
    "    pdq_dict = get_best_pdq(df_patient)\n",
    "    print(pdq_dict)\n",
    "    for metric in metrics:\n",
    "        print(f\"-----------------------------{metric}--------------------------------\")\n",
    "        pdq_order = int(max(pdq_dict[metric])+1)\n",
    "        X = df_patient[metric].values\n",
    "        error_values = []\n",
    "        for i in range(pdq_order, len(X)):\n",
    "            X_train = X[i-pdq_order:i]\n",
    "            X_test = X[i]\n",
    "            model = ARIMA(order=pdq_dict[metric])\n",
    "            X_predict = model.fit_predict(X_train, n_periods=1)\n",
    "            error = abs(X_predict - X_test)\n",
    "            error_values.append(error)\n",
    "        \n",
    "        squared_errors = [error ** 2 for error in error_values]\n",
    "        rmse = sqrt((sum(squared_errors))/len(squared_errors))\n",
    "        print(f\"RMSE for {metric}: {rmse}\")\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "#         plt.plot(X_train, y_train, color='grey')\n",
    "#         plt.plot(X_test, predictions_test, color='red')\n",
    "#         plt.plot(X_test, y_test, color='green')\n",
    "        \n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_and_predict2(df_patient, predict_n):\n",
    "    from pmdarima.arima import ARIMA\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    from math import sqrt\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "    metrics = ['SBP', 'SpO2', 'HR', 'RR', 'TEMP']\n",
    "    pdq_dict = get_best_pdq(df_patient)\n",
    "    print(pdq_dict)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        X = df_patient[metric].values\n",
    "        print(np.isinf(X).sum())\n",
    "        #size = int(max(pdq_dict[metric])+1)\n",
    "        size=10\n",
    "        train, test = X[0:size], X[size:len(X)]\n",
    "        history = [x for x in train]\n",
    "        predictions = []\n",
    "        print(f\"-----------------------------{metric}--------------------------------\")\n",
    "        \n",
    "        # rolling forecast to get rmse\n",
    "        for t in range(len(test)): \n",
    "            print(history)\n",
    "            model = ARIMA(order=(pdq_dict[metric]))\n",
    "            output = model.fit_predict(history, n_periods=2)\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "            print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "        # evaluate forecasts\n",
    "        rmse = sqrt(mean_squared_error(test, predictions))\n",
    "        print(f'Test RMSE {metric}: {rmse}')\n",
    "        \n",
    "        # predict next n samples\n",
    "        predict_metric = model.predict(n_periods=predict_n)\n",
    "        predict_metric_x = [i + len(test) for i in range(predict_n)]\n",
    "        predict_df = pd.DataFrame(data=predict_metric, index=predict_metric_x)\n",
    "        \n",
    "        print(predict_metric)\n",
    "        # plot forecasts against actual outcomes\n",
    "        plt.plot(test, color='grey')\n",
    "        plt.plot(predictions, color='red')\n",
    "        plt.plot(predict_df, color='green')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "model_and_predict2(patientx[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions that converts scores to EWS Total score**  \n",
    "Two scales for SpO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_news2_scale1 (rr, spo2, air_score, sbp, hr, loc_score, temp, check=False):\n",
    "    score = 0\n",
    "    # RR SCORE - normal values: 12-20\n",
    "    if rr <= 8 or rr >= 25:\n",
    "        rr_score = 3\n",
    "    elif 21 <= rr <= 24:\n",
    "        rr_score = 2\n",
    "    elif 9 <= rr <= 11:\n",
    "        rr_score = 1\n",
    "    else:\n",
    "        rr_score = 0\n",
    "    \n",
    "    # SPO2 SCORE - normal values: >= 96\n",
    "    if spo2 <= 91:\n",
    "        spo2_score = 3\n",
    "    elif 92 <= spo2 <= 93:\n",
    "        spo2_score = 2\n",
    "    elif 94 <= spo2 <= 95:\n",
    "        spo2_score = 1\n",
    "    else:\n",
    "        spo2_score = 0\n",
    "    \n",
    "    # OXYGEN METHOD SCORE \n",
    "    # 0 -> Room Air \n",
    "    # 3 -> Oxygen Mask\n",
    "    try:\n",
    "        assert air_score == 0 or air_score == 2, \"Air_score is not 0 or 2\"\n",
    "    except AssertionError:\n",
    "        raise\n",
    "    \n",
    "    # SBP SCORE - normal values: 111-219\n",
    "    if sbp <= 90 or sbp >= 220:\n",
    "        sbp_score = 3\n",
    "    elif 91 <= sbp <= 100:\n",
    "        sbp_score = 2\n",
    "    elif 101 <= sbp <= 110:\n",
    "        sbp_score = 1\n",
    "    else:\n",
    "        sbp_score = 0\n",
    "    \n",
    "    # HR SCORE - normal values: 51-90\n",
    "    if hr <= 40 or hr >= 131:\n",
    "        hr_score = 3\n",
    "    elif 111 <= hr <= 130:\n",
    "        hr_score = 2\n",
    "    elif 91 <= hr <= 110 or 41 <= hr <= 50:\n",
    "        hr_score = 1\n",
    "    else:\n",
    "        hr_score = 0\n",
    "    \n",
    "    # CONSCIOUSNESS METHOD SCORE \n",
    "    # 0 -> Alert \n",
    "    # 3 -> CVPU (Confusion, Voice, Pain, Unresponsive)\n",
    "    try:\n",
    "        assert loc_score == 0 or loc_score == 3, \"loc_score is not 0 or 3\"\n",
    "    except AssertionError:\n",
    "        raise\n",
    "    \n",
    "    # TEMP SCORE - normal values: 51-90\n",
    "    if temp <= 35.0:\n",
    "        temp_score = 3\n",
    "    elif temp > 39.1:\n",
    "        temp_score = 2\n",
    "    elif 35.1 <= temp <= 36.0 or 38.1 <= temp <= 39.0:\n",
    "        temp_score = 1\n",
    "    else:\n",
    "        temp_score = 0\n",
    "    \n",
    "    if check:\n",
    "        print(f'rr_score: {rr_score}')\n",
    "        print(f'spo2_score: {spo2_score}')\n",
    "        print(f'air_score: {air_score}')\n",
    "        print(f'sbp_score: {sbp_score}')\n",
    "        print(f'hr_score: {hr_score}')\n",
    "        print(f'loc_score: {loc_score}')\n",
    "        print(f'temp_score: {temp_score}')\n",
    "    \n",
    "    ews_total = rr_score + spo2_score + air_score + sbp_score + hr_score + loc_score + temp_score\n",
    "    \n",
    "    return ews_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_news2_scale2 (rr, spo2, air_score, sbp, hr, loc_score, temp, check=False):\n",
    "    score = 0\n",
    "    # RR SCORE - normal values: 12-20\n",
    "    if rr <= 8 or rr >= 25:\n",
    "        rr_score = 3\n",
    "    elif 21 <= rr <= 24:\n",
    "        rr_score = 2\n",
    "    elif 9 <= rr <= 11:\n",
    "        rr_score = 1\n",
    "    else:\n",
    "        rr_score = 0\n",
    "    \n",
    "    # SPO2 SCORE - normal values: >= 96\n",
    "    if spo2 <= 83 or spo2 >= 97:\n",
    "        spo2_score = 3\n",
    "    elif 84 <= spo2 <= 85 or 95 <= spo2 <= 96:\n",
    "        spo2_score = 2\n",
    "    elif 86 <= spo2 <= 87 or 93 <= spo2 <= 94:\n",
    "        spo2_score = 1\n",
    "    else:\n",
    "        spo2_score = 0\n",
    "    \n",
    "    # OXYGEN METHOD SCORE \n",
    "    # 0 -> Room Air \n",
    "    # 3 -> Oxygen Mask\n",
    "    try:\n",
    "        assert air_score == 0 or air_score == 2, \"Air_score is not 0 or 2\"\n",
    "    except AssertionError:\n",
    "        raise\n",
    "    \n",
    "    # SBP SCORE - normal values: 111-219\n",
    "    if sbp <= 90 or sbp >= 220:\n",
    "        sbp_score = 3\n",
    "    elif 91 <= sbp <= 100:\n",
    "        sbp_score = 2\n",
    "    elif 101 <= sbp <= 110:\n",
    "        sbp_score = 1\n",
    "    else:\n",
    "        sbp_score = 0\n",
    "    \n",
    "    # HR SCORE - normal values: 51-90\n",
    "    if hr <= 40 or hr >= 131:\n",
    "        hr_score = 3\n",
    "    elif 111 <= hr <= 130:\n",
    "        hr_score = 2\n",
    "    elif 91 <= hr <= 110 or 41 <= hr <= 50:\n",
    "        hr_score = 1\n",
    "    else:\n",
    "        hr_score = 0\n",
    "    \n",
    "    # CONSCIOUSNESS METHOD SCORE \n",
    "    # 0 -> Alert \n",
    "    # 3 -> CVPU (Confusion, Voice, Pain, Unresponsive)\n",
    "    try:\n",
    "        assert loc_score == 0 or loc_score == 3, \"loc_score is not 0 or 3\"\n",
    "    except AssertionError:\n",
    "        raise\n",
    "    \n",
    "    # TEMP SCORE - normal values: 51-90\n",
    "    if temp <= 35.0:\n",
    "        temp_score = 3\n",
    "    elif temp > 39.1:\n",
    "        temp_score = 2\n",
    "    elif 35.1 <= temp <= 36.0 or 38.1 <= temp <= 39.0:\n",
    "        temp_score = 1\n",
    "    else:\n",
    "        temp_score = 0\n",
    "    \n",
    "    if check:\n",
    "        print(f'rr_score: {rr_score}')\n",
    "        print(f'spo2_score: {spo2_score}')\n",
    "        print(f'air_score: {air_score}')\n",
    "        print(f'sbp_score: {sbp_score}')\n",
    "        print(f'hr_score: {hr_score}')\n",
    "        print(f'loc_score: {loc_score}')\n",
    "        print(f'temp_score: {temp_score}')\n",
    "    \n",
    "    ews_total = rr_score + spo2_score + air_score + sbp_score + hr_score + loc_score + temp_score\n",
    "    \n",
    "    return ews_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hit_acc (df, samples, to_print=False):\n",
    "# if there is a hit with either of the scales it will append true to this list\n",
    "    check_row = []\n",
    "    test_df = df.sample(n=samples)\n",
    "    # check every row and apply calculate_news2_scale1\n",
    "    for index, row in test_df.iterrows():\n",
    "        ews_row_calc = calculate_news2_scale1(rr=row.RR, spo2=row.SpO2, air_score=row.Add_O2_Score, sbp=row.SBP, \n",
    "                                       hr=row.HR, loc_score=row.LOC_Score, temp=row.TEMP, check=to_print)\n",
    "        if int(ews_row_calc) == int(row.EWS_Total):\n",
    "            check_row.append(True)\n",
    "            if to_print == True:\n",
    "                print(\"-----\")\n",
    "        # if this isn't a hit, apply calculate_news2_scale2 \n",
    "        else:\n",
    "            ews_row_calc_2 = calculate_news2_scale2(rr=row.RR, spo2=row.SpO2, air_score=row.Add_O2_Score, sbp=row.SBP, \n",
    "                                       hr=row.HR, loc_score=row.LOC_Score, temp=row.TEMP, check=to_print)\n",
    "            if ews_row_calc_2 == int(row.EWS_Total):\n",
    "                check_row.append(True)\n",
    "                if to_print == True:\n",
    "                    print(\"-----\")\n",
    "            # if both of the calculate methods fail, false will be appended to the list\n",
    "            else:\n",
    "                check_row.append(False)\n",
    "                if to_print == True:\n",
    "                    print(f\"{row.name}: false\")\n",
    "                    print(f\"calculated: {ews_row_calc} != given: {row.EWS_Total}\")\n",
    "                    print(\"-----\")\n",
    "    # print the accuracy of this function\n",
    "    hit_perc = (check_row.count(True)/len(check_row))*100\n",
    "    print(f\"Accuracy of function: {hit_perc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_acc_50 = check_hit_acc(df, samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
